{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"read\").\\\n",
    "    enableHiveSupport().\\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"./source.csv\", sep=\",\",\n",
    "                    header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|source_id|     source_username|\n",
      "+---------+--------------------+\n",
      "|   100137|    Merlene Blodgett|\n",
      "|   103582|         Carmen Cura|\n",
      "|   106463|     Richard Sanchez|\n",
      "|   119403|      Betty De Hoyos|\n",
      "|   119555|      Socorro Quiara|\n",
      "|   119868| Michelle San Miguel|\n",
      "|   120752|      Eva T. Kleiber|\n",
      "|   124405|           Lori Lara|\n",
      "|   132408|       Leonard Silva|\n",
      "|   135723|        Amy Cardenas|\n",
      "|   136202|    Michelle Urrutia|\n",
      "|   136979|      Leticia Garcia|\n",
      "|   137943|    Pamela K. Baccus|\n",
      "|   138605|        Marisa Ozuna|\n",
      "|   138650|      Kimberly Green|\n",
      "|   138650|Kimberly Green-Woods|\n",
      "|   138793| Guadalupe Rodriguez|\n",
      "|   138810|       Tawona Martin|\n",
      "|   139342|     Jessica Mendoza|\n",
      "|   139344|        Isis Mendoza|\n",
      "+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100137</td>\n",
       "      <td>Merlene Blodgett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103582</td>\n",
       "      <td>Carmen Cura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106463</td>\n",
       "      <td>Richard Sanchez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119403</td>\n",
       "      <td>Betty De Hoyos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119555</td>\n",
       "      <td>Socorro Quiara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_id   source_username\n",
       "0    100137  Merlene Blodgett\n",
       "1    103582       Carmen Cura\n",
       "2    106463   Richard Sanchez\n",
       "3    119403    Betty De Hoyos\n",
       "4    119555    Socorro Quiara"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pd = pd.read_csv(\"./source.csv\", sep=\",\")\n",
    "df_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|source_id| source_username|\n",
      "+---------+----------------+\n",
      "|   100137|Merlene Blodgett|\n",
      "|   103582|     Carmen Cura|\n",
      "|   106463| Richard Sanchez|\n",
      "|   119403|  Betty De Hoyos|\n",
      "|   119555|  Socorro Quiara|\n",
      "+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To Spark from Pandas\n",
    "df_spark = spark.createDataFrame(df_pd)\n",
    "df_spark.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100137</td>\n",
       "      <td>Merlene Blodgett</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103582</td>\n",
       "      <td>Carmen Cura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106463</td>\n",
       "      <td>Richard Sanchez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119403</td>\n",
       "      <td>Betty De Hoyos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119555</td>\n",
       "      <td>Socorro Quiara</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_id   source_username\n",
       "0    100137  Merlene Blodgett\n",
       "1    103582       Carmen Cura\n",
       "2    106463   Richard Sanchez\n",
       "3    119403    Betty De Hoyos\n",
       "4    119555    Socorro Quiara"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark DataFrame to Pandas DataFrame\n",
    "df_pd = df_spark.toPandas()\n",
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid   # Create unique table name\n",
    "table_name = \"df_\" + str(uuid.uuid4().hex)  \n",
    "df.write.saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|      source_id|   string|   null|\n",
      "|source_username|   string|   null|\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"DESCRIBE %s\" % table_name\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_daf213f7773247cbb1f6d7dd92d24095'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|df_daf213f7773247...|      false|\n",
      "+--------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE default\")\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|      source_id|   string|   null|\n",
      "|source_username|   string|   null|\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE {table_name}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+\n",
      "|source_id|    source_username|\n",
      "+---------+-------------------+\n",
      "|   100137|   Merlene Blodgett|\n",
      "|   103582|        Carmen Cura|\n",
      "|   106463|    Richard Sanchez|\n",
      "|   119403|     Betty De Hoyos|\n",
      "|   119555|     Socorro Quiara|\n",
      "|   119868|Michelle San Miguel|\n",
      "|   120752|     Eva T. Kleiber|\n",
      "|   124405|          Lori Lara|\n",
      "|   132408|      Leonard Silva|\n",
      "|   135723|       Amy Cardenas|\n",
      "+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM {table_name} LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|source_id| source_username|\n",
      "+---------+----------------+\n",
      "|   100137|Merlene Blodgett|\n",
      "|   103582|     Carmen Cura|\n",
      "|   106463| Richard Sanchez|\n",
      "|   119403|  Betty De Hoyos|\n",
      "|   119555|  Socorro Quiara|\n",
      "+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(f\"SELECT * FROM {table_name}\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.range(1000).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|            uniform|\n",
      "+---+-------------------+\n",
      "|  0| 0.3217855146445381|\n",
      "|  1| 0.5926558057691951|\n",
      "|  2| 0.3530876039804548|\n",
      "|  3|0.18715752944048802|\n",
      "|  4| 0.9700656793032243|\n",
      "+---+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "spark.range(1000).withColumn(\"uniform\", rand(12345)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random Bernoulli random variable with p = 0.25\n",
    "\n",
    "df = spark.range(1000). \\\n",
    "  withColumn(\"Bernoulli\", (rand(12345) < 0.25). \\\n",
    "  cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Bernoulli|count|\n",
      "+---------+-----+\n",
      "|        0|  753|\n",
      "|        1|  247|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a summary using the functional style:\n",
    "df.groupby(\"Bernoulli\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Bernoulli|count|\n",
      "+---------+-----+\n",
      "|        0|  753|\n",
      "|        1|  247|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"bern\")\n",
    "spark.sql(\"SELECT Bernoulli, COUNT(*) AS count \\\n",
    "            FROM bern \\\n",
    "            GROUP BY Bernoulli\"). \\\n",
    "  show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "| id|            normal|\n",
      "+---+------------------+\n",
      "|  0|45.362885425117504|\n",
      "|  1| 42.41317857967899|\n",
      "|  2|46.135931767491265|\n",
      "|  3| 39.81112359797484|\n",
      "|  4| 44.19365809728162|\n",
      "+---+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import randn\n",
    "mydf = spark.range(1000).withColumn(\"normal\", 42 +  2 * randn(54321))\n",
    "mydf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+\n",
      "|summary|               id|            normal|\n",
      "+-------+-----------------+------------------+\n",
      "|  count|             1000|              1000|\n",
      "|   mean|            499.5| 41.98776215302001|\n",
      "| stddev|288.8194360957494|2.0072883619960256|\n",
      "|    min|                0|35.820280013529704|\n",
      "|    max|              999| 48.94773330054072|\n",
      "+-------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mydf.describe(\"id\", \"normal\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
